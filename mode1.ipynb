{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b505317-544a-4957-8735-bd1b70a0a571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face_recognition in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.3.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.24.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from face_recognition) (8.2.1)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from face_recognition) (20.0.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from face_recognition) (10.2.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\daara\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install face_recognition scikit-learn xgboost numpy matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac386415-0b90-4343-8d2e-d07d982f3e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current files in known_faces:\n",
      "📁 .ipynb_checkpoints/\n",
      "📁 Amar/\n",
      "  ├─ .ipynb_checkpoints\n",
      "  ├─ Amar_1.jpg\n",
      "  ├─ person1_2.jpg\n",
      "📁 Arpita_singh/\n",
      "  ├─ .ipynb_checkpoints\n",
      "  ├─ Arpita_singh.png\n",
      "📁 person1/\n",
      "  ├─ .ipynb_checkpoints\n",
      "  ├─ sample.jpg\n",
      "📁 person2/\n",
      "  ├─ .ipynb_checkpoints\n",
      "  ├─ person2_1.jpg\n",
      "  ├─ person2_1749916628.jpg\n",
      "📁 ronaldo/\n",
      "  ├─ .ipynb_checkpoints\n",
      "  ├─ ronaldo_1.jpg\n",
      "\n",
      "Reorganization complete! New structure:\n",
      "\n",
      "👤 .ipynb_checkpoints:\n",
      "\n",
      "👤 Amar:\n",
      "  - .ipynb_checkpoints\n",
      "  - Amar_1.jpg\n",
      "  - person1_2.jpg\n",
      "\n",
      "👤 Arpita_singh:\n",
      "  - .ipynb_checkpoints\n",
      "  - Arpita_singh.png\n",
      "\n",
      "👤 person1:\n",
      "  - .ipynb_checkpoints\n",
      "  - sample.jpg\n",
      "\n",
      "👤 person2:\n",
      "  - .ipynb_checkpoints\n",
      "  - person2_1.jpg\n",
      "  - person2_1749916628.jpg\n",
      "\n",
      "👤 ronaldo:\n",
      "  - .ipynb_checkpoints\n",
      "  - ronaldo_1.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "# 1. First verify current structure\n",
    "print(\"Current files in known_faces:\")\n",
    "for item in os.listdir(\"known_faces\"):\n",
    "    item_path = os.path.join(\"known_faces\", item)\n",
    "    if os.path.isdir(item_path):\n",
    "        print(f\"📁 {item}/\")\n",
    "        for subitem in os.listdir(item_path):\n",
    "            print(f\"  ├─ {subitem}\")\n",
    "    else:\n",
    "        print(f\"📄 {item}\")\n",
    "\n",
    "# 2. Reorganization code - ADJUSTED FOR YOUR ACTUAL STRUCTURE\n",
    "try:\n",
    "    # Convert WebP to JPG for person2\n",
    "    webp_path = \"known_faces/person2/mesh.webp\"\n",
    "    if os.path.exists(webp_path):\n",
    "        img = Image.open(webp_path).convert(\"RGB\")\n",
    "        jpg_path = \"known_faces/person2/person2_1.jpg\"\n",
    "        img.save(jpg_path)\n",
    "        os.remove(webp_path)\n",
    "        print(f\"\\n✅ Converted {webp_path} to {jpg_path}\")\n",
    "    \n",
    "    # Rename person1's image\n",
    "    old_path = \"known_faces/person1/myface.jpg\"\n",
    "    new_path = \"known_faces/person1/person1_1.jpg\"\n",
    "    if os.path.exists(old_path):\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\"✅ Renamed {old_path} to {new_path}\")\n",
    "    \n",
    "    # No ronaldo.jpg exists based on your screenshots\n",
    "    # If you have it, please specify its exact location\n",
    "    \n",
    "    print(\"\\nReorganization complete! New structure:\")\n",
    "    for person in os.listdir(\"known_faces\"):\n",
    "        if os.path.isdir(os.path.join(\"known_faces\", person)):\n",
    "            print(f\"\\n👤 {person}:\")\n",
    "            for img in os.listdir(os.path.join(\"known_faces\", person)):\n",
    "                print(f\"  - {img}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error occurred: {str(e)}\")\n",
    "    print(\"Please check:\")\n",
    "    print(\"1. File paths are correct\")\n",
    "    print(\"2. Files actually exist in the shown locations\")\n",
    "    print(\"3. You have proper permissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e45a4328-e01f-497e-addb-34d2759959c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanup complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Remove hidden checkpoints folders\n",
    "for root, dirs, files in os.walk(\"known_faces\"):\n",
    "    if '.ipynb_checkpoints' in dirs:\n",
    "        shutil.rmtree(os.path.join(root, '.ipynb_checkpoints'))\n",
    "        print(f\"Removed {os.path.join(root, '.ipynb_checkpoints')}\")\n",
    "\n",
    "# Move loose files to correct folders\n",
    "if os.path.exists(\"known_faces/myyface.jpg\"):\n",
    "    shutil.move(\"known_faces/myyface.jpg\", \"known_faces/person1/myyface.jpg\")\n",
    "if os.path.exists(\"known_faces/mesi.webp\"):\n",
    "    shutil.move(\"known_faces/mesi.webp\", \"known_faces/person2/mesi.webp\")\n",
    "\n",
    "print(\"Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36414449-4ad3-4a7d-a214-5cd8f29053a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "TARGET_IMAGES = 5\n",
    "RECOG_THRESH = 0.45\n",
    "FRAME_SCALE = 0.5\n",
    "PROCESS_EVERY = 2\n",
    "\n",
    "def setup_dirs():\n",
    "    os.makedirs(\"known_faces/Amar\", exist_ok=True)\n",
    "    os.makedirs(\"known_faces/Arpita_singh\", exist_ok=True)\n",
    "\n",
    "def load_encodings_fast():\n",
    "    encodings = []\n",
    "    names = []\n",
    "    \n",
    "    for person in [\"Amar\", \"Arpita_singh\"]:\n",
    "        person_dir = f\"known_faces/{person}\"\n",
    "        if not os.path.exists(person_dir):\n",
    "            continue\n",
    "            \n",
    "        for img_file in os.listdir(person_dir)[:5]:\n",
    "            if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                continue\n",
    "                \n",
    "            img_path = f\"{person_dir}/{img_file}\"\n",
    "            image = face_recognition.load_image_file(img_path)\n",
    "            face_locs = face_recognition.face_locations(image)\n",
    "            \n",
    "            if face_locs:\n",
    "                enc = face_recognition.face_encodings(image, known_face_locations=face_locs, num_jitters=1, model=\"small\")\n",
    "                if enc:\n",
    "                    encodings.append(enc[0])\n",
    "                    names.append(person)\n",
    "    \n",
    "    return encodings, names\n",
    "\n",
    "def main():\n",
    "    setup_dirs()\n",
    "    known_encs, known_names = load_encodings_fast()\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            frame_count += 1\n",
    "            if frame_count % PROCESS_EVERY != 0:\n",
    "                continue\n",
    "                \n",
    "            small_frame = cv2.resize(frame, (0, 0), fx=FRAME_SCALE, fy=FRAME_SCALE)\n",
    "            rgb_small = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "            face_locs = face_recognition.face_locations(rgb_small, number_of_times_to_upsample=1, model=\"hog\")\n",
    "            \n",
    "            display_frame = frame.copy()\n",
    "            \n",
    "            # Get current time\n",
    "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            \n",
    "            for (top, right, bottom, left) in face_locs:\n",
    "                top *= 2; right *= 2; bottom *= 2; left *= 2\n",
    "                \n",
    "                face_enc = face_recognition.face_encodings(\n",
    "                    rgb_small,\n",
    "                    known_face_locations=[(top//2, right//2, bottom//2, left//2)],\n",
    "                    num_jitters=1,\n",
    "                    model=\"small\"\n",
    "                )\n",
    "                \n",
    "                if face_enc and known_encs:\n",
    "                    dists = face_recognition.face_distance(known_encs, face_enc[0])\n",
    "                    best_idx = np.argmin(dists)\n",
    "                    confidence = (1 - dists[best_idx]) * 100\n",
    "                    \n",
    "                    if dists[best_idx] < RECOG_THRESH:\n",
    "                        name = known_names[best_idx]\n",
    "                        color = (0, 255, 0)\n",
    "                        status = f\"{name} {confidence:.1f}%\"\n",
    "                    else:\n",
    "                        status = \"Unknown\"\n",
    "                        color = (0, 0, 255)\n",
    "                    \n",
    "                    cv2.rectangle(display_frame, (left, top), (right, bottom), color, 2)\n",
    "                    cv2.putText(display_frame, status, (left + 6, bottom + 25), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)\n",
    "            \n",
    "            # Display different information on left side\n",
    "            cv2.putText(display_frame, current_time, (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "            cv2.putText(display_frame, f\"Faces: {len(face_locs)}\", (10, 60), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 1)\n",
    "            cv2.putText(display_frame, \"SPACE:Capture | Q:Quit\", (10, 90), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)\n",
    "            \n",
    "            cv2.imshow('Face Recognition', display_frame)\n",
    "            \n",
    "            key = cv2.waitKey(1)\n",
    "            if key in [ord('q'), ord('Q')]:\n",
    "                break\n",
    "            elif key == 32 and face_locs:\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                img_path = f\"known_faces/Amar/Amar_{timestamp}.jpg\"\n",
    "                cv2.imwrite(img_path, frame)\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bacffb-f639-4c6f-b76a-aeed3c238f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
