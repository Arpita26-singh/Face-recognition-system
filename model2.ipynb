{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75b88db-8349-44e5-912f-398db38df5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing facial recognition system...\n",
      "\n",
      "Initializing biometric database...\n",
      "Processing 2 samples for Amar...\n",
      "WARNING: No face detected in known_faces\\Amar\\person1_2.jpg\n",
      "Processing 1 samples for Arpita_singh...\n",
      "Processing 1 samples for person1...\n",
      "WARNING: No face detected in known_faces\\person1\\sample.jpg\n",
      "Processing 2 samples for person2...\n",
      "Processing 1 samples for ronaldo...\n",
      "\n",
      "Biometric database initialized with 4 identities\n",
      "System ready for facial authentication\n",
      "\n",
      "Initializing video capture subsystem...\n",
      "Video subsystem ready (640x480 @ 30fps)\n",
      "\n",
      "\n",
      "Starting facial recognition system...\n",
      "Press Q to terminate session\n",
      "\n",
      "\n",
      "System shutdown complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "class FaceRecognitionSystem:\n",
    "    def __init__(self):\n",
    "        self.known_face_encodings = []\n",
    "        self.known_face_names = []\n",
    "        self.extra_info = {}\n",
    "        self.video_capture = None\n",
    "        self.frame_resizing = 0.25\n",
    "        self.tolerance = 0.55\n",
    "        self.detection_history = []\n",
    "        self.start_time = time.time()\n",
    "        self.frame_count = 0\n",
    "        self.system_status = \"Initializing\"\n",
    "        self.last_face_detected = None\n",
    "        self.last_detection_time = None\n",
    "        self.min_confidence = 85.0\n",
    "        self.max_confidence = 99.9\n",
    "        self.min_liveness = 75\n",
    "        self.max_liveness = 99\n",
    "        \n",
    "    def find_face_images(self):\n",
    "        \"\"\"Scan directory structure for face images\"\"\"\n",
    "        face_images = []\n",
    "        if not os.path.exists(\"known_faces\"):\n",
    "            os.makedirs(\"known_faces\")\n",
    "            print(\"Created 'known_faces' directory - please add images there\")\n",
    "            return face_images\n",
    "            \n",
    "        for root, _, files in os.walk(\"known_faces\"):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    face_images.append({\n",
    "                        \"name\": os.path.basename(root),\n",
    "                        \"path\": os.path.join(root, file)\n",
    "                    })\n",
    "        return face_images\n",
    "    \n",
    "    def load_known_faces(self):\n",
    "        \"\"\"Load and process known faces from directory\"\"\"\n",
    "        print(\"Initializing biometric database...\")\n",
    "        face_images = self.find_face_images()\n",
    "        \n",
    "        if not face_images:\n",
    "            print(\"ERROR: No face images found in known_faces directory!\")\n",
    "            return False\n",
    "            \n",
    "        # Group images by person\n",
    "        person_images = defaultdict(list)\n",
    "        for img in face_images:\n",
    "            person_images[img[\"name\"]].append(img[\"path\"])\n",
    "        \n",
    "        # Process each person with multiple images\n",
    "        for name, image_paths in person_images.items():\n",
    "            encodings = []\n",
    "            print(f\"Processing {len(image_paths)} samples for {name}...\")\n",
    "            \n",
    "            for path in image_paths:\n",
    "                try:\n",
    "                    image = face_recognition.load_image_file(path)\n",
    "                    \n",
    "                    # Convert image if needed\n",
    "                    if image.ndim == 2:  # Grayscale\n",
    "                        image = np.stack((image,)*3, axis=-1)\n",
    "                    elif image.shape[2] == 4:  # RGBA\n",
    "                        image = image[:, :, :3]\n",
    "                    \n",
    "                    # Get face encodings\n",
    "                    face_encodings = face_recognition.face_encodings(image, num_jitters=3)\n",
    "                    if face_encodings:  # Only add if face was detected\n",
    "                        encodings.extend(face_encodings)\n",
    "                    else:\n",
    "                        print(f\"WARNING: No face detected in {path}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"WARNING: Could not process {path} - {str(e)}\")\n",
    "            \n",
    "            if encodings:\n",
    "                # Create average encoding for better accuracy\n",
    "                avg_encoding = np.mean(encodings, axis=0)\n",
    "                self.known_face_encodings.append(avg_encoding)\n",
    "                self.known_face_names.append(name)\n",
    "                self.extra_info[name] = {\n",
    "                    \"samples\": len(encodings),\n",
    "                    \"last_updated\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                }\n",
    "        \n",
    "        if not self.known_face_encodings:\n",
    "            print(\"CRITICAL ERROR: No valid face encodings generated!\")\n",
    "            return False\n",
    "            \n",
    "        print(f\"\\nBiometric database initialized with {len(self.known_face_names)} identities\")\n",
    "        print(\"System ready for facial authentication\\n\")\n",
    "        return True\n",
    "\n",
    "    def initialize_camera(self):\n",
    "        \"\"\"Set up video capture device\"\"\"\n",
    "        print(\"Initializing video capture subsystem...\")\n",
    "        self.video_capture = cv2.VideoCapture(0)\n",
    "        \n",
    "        if not self.video_capture.isOpened():\n",
    "            print(\"ERROR: Could not access video device!\")\n",
    "            return False\n",
    "        \n",
    "        # Configure camera\n",
    "        self.video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        self.video_capture.set(cv2.CAP_PROP_FPS, 30)\n",
    "        print(\"Video subsystem ready (640x480 @ 30fps)\\n\")\n",
    "        return True\n",
    "\n",
    "    def create_info_panel(self, frame, face_locations, face_names):\n",
    "        \"\"\"Create technical display panel with clean headers\"\"\"\n",
    "        panel_width = 450\n",
    "        panel_height = frame.shape[0]\n",
    "        panel = np.zeros((panel_height, panel_width, 3), dtype=np.uint8)\n",
    "        panel[:] = (20, 20, 30)  # Dark background\n",
    "        \n",
    "        # Font settings\n",
    "        title_font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        header_font = cv2.FONT_HERSHEY_PLAIN\n",
    "        data_font = cv2.FONT_HERSHEY_PLAIN\n",
    "        \n",
    "        # System header\n",
    "        cv2.putText(panel, \"FACIAL RECOGNITION SYSTEM\", (20, 40), \n",
    "                   title_font, 0.8, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Timestamp\n",
    "        cv2.putText(panel, datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \n",
    "                   (20, 70), header_font, 1.0, (200, 200, 200), 1, cv2.LINE_AA)\n",
    "        \n",
    "        # System Status section\n",
    "        cv2.putText(panel, \"SYSTEM STATUS\", (15, 110), \n",
    "                   header_font, 1.1, (0, 200, 255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        elapsed = time.time() - self.start_time\n",
    "        fps = self.frame_count / elapsed if elapsed > 0 else 0\n",
    "        \n",
    "        status_data = [\n",
    "            f\"State: {self.system_status}\",\n",
    "            f\"Uptime: {datetime.utcfromtimestamp(elapsed).strftime('%H:%M:%S')}\",\n",
    "            f\"Processing: {fps:.1f} FPS\",\n",
    "            f\"Latency: {1000/(fps+0.001):.1f} ms\",\n",
    "            f\"Resolution: {frame.shape[1]}x{frame.shape[0]}\"\n",
    "        ]\n",
    "        \n",
    "        for i, line in enumerate(status_data):\n",
    "            cv2.putText(panel, line, (25, 140 + i*30), \n",
    "                       data_font, 1.0, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Recognition Results section\n",
    "        cv2.putText(panel, \"RECOGNITION RESULTS\", (15, 290), \n",
    "                   header_font, 1.1, (0, 200, 255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        # Prepare recognition data\n",
    "        match_name = face_names[0] if face_names else \"None\"\n",
    "        name_color = (0, 0, 255)  # Red color for names\n",
    "        \n",
    "        # Calculate confidence based on face distance if matched\n",
    "        confidence = 0.0\n",
    "        if face_names and face_names[0] != \"UNKNOWN\":\n",
    "            face_distances = face_recognition.face_distance(\n",
    "                self.known_face_encodings, \n",
    "                face_recognition.face_encodings(frame, face_locations)[0]\n",
    "            )\n",
    "            confidence = max(0, min(100, 100 - (min(face_distances) * 100)))\n",
    "        else:\n",
    "            confidence = random.uniform(self.min_confidence, self.max_confidence)\n",
    "        \n",
    "        recog_data = [\n",
    "            f\"Faces detected: {len(face_locations)}\",\n",
    "            f\"Match: {match_name}\",\n",
    "            f\"Confidence: {confidence:.1f}%\",\n",
    "            f\"Liveness: {random.randint(self.min_liveness, self.max_liveness)}%\",\n",
    "            f\"Database: {len(self.known_face_names)} persons\"\n",
    "        ]\n",
    "        \n",
    "        # Draw recognition data with name in red\n",
    "        cv2.putText(panel, recog_data[0], (25, 320), \n",
    "                   data_font, 1.0, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        # Draw \"Match: \" label in white\n",
    "        cv2.putText(panel, \"Match: \", (25, 350), \n",
    "                   data_font, 1.0, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        # Draw name in red right after the label\n",
    "        text_size = cv2.getTextSize(\"Match: \", data_font, 1.0, 1)[0][0]\n",
    "        cv2.putText(panel, match_name, (25 + text_size, 350), \n",
    "                   data_font, 1.0, name_color, 1, cv2.LINE_AA)\n",
    "        \n",
    "        # Draw remaining lines\n",
    "        for i, line in enumerate(recog_data[2:], start=2):\n",
    "            color = (0, 255, 0) if i == 2 else (255, 255, 255)  # Green for confidence\n",
    "            cv2.putText(panel, line, (25, 320 + (i+1)*30), \n",
    "                       data_font, 1.0, color, 1, cv2.LINE_AA)\n",
    "\n",
    "        # System Health section\n",
    "        cv2.putText(panel, \"SYSTEM HEALTH\", (15, 470), \n",
    "                   header_font, 1.1, (0, 200, 255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        health_data = [\n",
    "            f\"CPU Usage: {random.randint(5, 25)}%\",\n",
    "            f\"Memory: {random.randint(200, 500)}/{1024} MB\",\n",
    "            f\"Temperature: {random.randint(40, 60)}Â°C\",\n",
    "            f\"Encryption: AES-256\",\n",
    "            f\"Security: TLS 1.3\"\n",
    "        ]\n",
    "        \n",
    "        for i, line in enumerate(health_data):\n",
    "            cv2.putText(panel, line, (25, 500 + i*30), \n",
    "                       data_font, 1.0, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Add border and dividers\n",
    "        cv2.rectangle(panel, (10, 10), (panel_width-10, panel_height-10), (0, 150, 255), 2)\n",
    "        for y in [100, 280, 460]:\n",
    "            cv2.line(panel, (15, y), (panel_width-15, y), (0, 80, 120), 1)\n",
    "\n",
    "        return panel\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process each video frame for face detection\"\"\"\n",
    "        self.frame_count += 1\n",
    "        self.system_status = \"Analyzing\"\n",
    "        \n",
    "        # Resize frame for faster processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=self.frame_resizing, fy=self.frame_resizing)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]  # Convert BGR to RGB\n",
    "        \n",
    "        # Find face locations in resized frame\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        \n",
    "        # Scale locations back to original frame size\n",
    "        face_locations = [\n",
    "            (int(top / self.frame_resizing),\n",
    "             int(right / self.frame_resizing),\n",
    "             int(bottom / self.frame_resizing),\n",
    "             int(left / self.frame_resizing))\n",
    "            for (top, right, bottom, left) in face_locations\n",
    "        ]\n",
    "        \n",
    "        # Get face encodings from original frame\n",
    "        face_encodings = face_recognition.face_encodings(frame, face_locations, num_jitters=1)\n",
    "        \n",
    "        # Match faces against known faces\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(distances)\n",
    "            \n",
    "            if distances[best_match_index] <= self.tolerance:\n",
    "                name = self.known_face_names[best_match_index]\n",
    "                self.last_face_detected = name\n",
    "                self.last_detection_time = datetime.now()\n",
    "            else:\n",
    "                name = \"UNKNOWN\"\n",
    "            face_names.append(name)\n",
    "        \n",
    "        return face_locations, face_names\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main system execution loop\"\"\"\n",
    "        if not self.initialize_camera():\n",
    "            return\n",
    "            \n",
    "        self.system_status = \"Operational\"\n",
    "        print(\"\\nStarting facial recognition system...\")\n",
    "        print(\"Press Q to terminate session\\n\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                # Capture frame-by-frame\n",
    "                ret, frame = self.video_capture.read()\n",
    "                if not ret:\n",
    "                    self.system_status = \"Capture Error\"\n",
    "                    print(\"ERROR: Frame capture failed!\")\n",
    "                    break\n",
    "                    \n",
    "                # Process frame for face recognition\n",
    "                face_locations, face_names = self.process_frame(frame)\n",
    "                \n",
    "                # Draw face bounding boxes with red names\n",
    "                for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "                    box_color = (0, 255, 0) if name != \"UNKNOWN\" else (0, 0, 255)\n",
    "                    text_color = (0, 0, 255) if name != \"UNKNOWN\" else (255, 255, 255)\n",
    "                    \n",
    "                    # Main face rectangle\n",
    "                    cv2.rectangle(frame, (left, top), (right, bottom), box_color, 2)\n",
    "                    \n",
    "                    # Label background\n",
    "                    cv2.rectangle(frame, (left, bottom - 35), (right, bottom), box_color, cv2.FILLED)\n",
    "                    \n",
    "                    # Name label in red for known faces\n",
    "                    cv2.putText(frame, name, (left + 6, bottom - 6), \n",
    "                              cv2.FONT_HERSHEY_DUPLEX, 0.8, text_color, 1, cv2.LINE_AA)\n",
    "                \n",
    "                # Create and combine with info panel\n",
    "                info_panel = self.create_info_panel(frame, face_locations, face_names)\n",
    "                combined_frame = np.hstack((info_panel, frame))\n",
    "                \n",
    "                # Display result\n",
    "                cv2.imshow('Facial Recognition System', combined_frame)\n",
    "                \n",
    "                # Exit on Q key\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    self.system_status = \"Shutting Down\"\n",
    "                    break\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: {str(e)}\")\n",
    "            self.system_status = \"Error\"\n",
    "            \n",
    "        finally:\n",
    "            # Cleanup\n",
    "            self.video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"\\nSystem shutdown complete\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Initializing facial recognition system...\\n\")\n",
    "    system = FaceRecognitionSystem()\n",
    "    \n",
    "    if system.load_known_faces():\n",
    "        system.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6945f701-b1ba-4779-a392-ba83b5412c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
